MeterGPT 的核心概念與代理人協作
MeterGPT 系統的設計理念是將 MetaGPT 的多代理人框架應用於儀器讀值，這意味著它為大型語言模型 (GPT)——在此案例中，是廣義的 AI 模型和演算法——分配不同的角色，以形成一個協作實體來執行複雜的任務。其核心哲學是 「Code = SOP(Team)」，將精心編排的標準作業程序 (SOPs) 實體化，確保各模組協同作業以實現可靠、零遺漏、零誤抄的儀器讀值目標。
MeterGPT 系統將儀器讀值任務拆解為多個子目標，並為每個子目標分配了相應的「角色」或模組，這些模組協同運作，類似於一個軟體公司內部的不同職位。
每個代理人（模組）的任務詳述
1.
StreamHub (中心節點)
◦
任務： 作為資料的中心匯流排，持續接收來自每台 PTZ (Pan-Tilt-Zoom) 攝影機的影像串流。它類似於資料總線或數據入口，確保所有原始影像數據的集中管理和可用性。
◦
協作角色： 可以想像成軟體公司的「版本控制系統」或「資料湖」，是所有原始資料的集中存放地。
2.
儀器偵測模型 (Instrument Detection Model)
◦
任務： 負責從影像中偵測「哪裡有儀器」，並初步判斷儀器型號。它使用 YOLOv8m 以上或 RT-DETR 等物件偵測模型。偵測的標籤可能包括：數位螢幕、七段顯示器、指針錶盤等。
◦
特色/挑戰： 需考慮現場光線可能受手術燈、警示燈干擾，需要進行 HDR 風格增強訓練以提高魯棒性。
◦
協作角色： 類似於「需求分析師」或「前置處理單元」，負責從海量數據中識別出關鍵的目標物件並進行初步分類。
3.
角點偵測模型 (Corner Point Detection Model)
◦
任務： 在儀器偵測模型裁切出的影像中，進一步偵測螢幕的四個角點座標。這些角點用於計算透視矩陣，以便將傾斜的畫面「拉正」，進行透視校正，這對於數位讀值 OCR（尤其是處理眩光、斜視）非常關鍵。
◦
協作角色： 類似於「架構師」或「幾何校準專家」，提供精確的空間校準資訊，為後續的精確讀值奠定基礎。
4.
模板-ROI 切割器 (Template-ROI Cutter)
◦
任務： 根據儀器型號的 YAML 列表（預定義的儀器模板），一次性切割出所有關鍵欄位的感興趣區域 (ROI)。這些欄位可能包括七段顯示區域、LCD 螢幕區域等。
◦
協作角色： 類似於「資料工程師」或「資料預處理單元」，精準地準備用於分析的資料片段，確保 OCR 只處理必要的區域。
5.
OCR 管線 (OCR Pipeline)
◦
任務： 對於模板-ROI 切割器提供的 ROI，進行快速的數值讀取。
▪
七段顯示： 通常使用基於規則 (rule-based) 的解析。
▪
LCD 螢幕： 則使用小型 CRNN (Convolutional Recurrent Neural Network) 模型，或 PaddleOCR。
◦
特色/注意事項：
▪
速度與幀率： 相比純 VLM，Detection + OCR 方法在速度上有顯著優勢，七段或 LCD OCR 每張影像可低於 5 毫秒，CPU 也能運行，能穩定支援 10-30 fps 的處理。
▪
可解釋性： 可回溯到具體 ROI 與像素，便於錯誤定位和製作黃金樣本。
▪
法規合規： 主流程為可決定論的算法，審查負擔較小，更易合規。
◦
協作角色： 類似於「核心演算法工程師」，執行精確的數值提取，是日常高頻讀值的主幹。
6.
VLM Orchestrator (大型視覺語言模型協調器)
◦
任務： 當幾何失準、標籤不確定或 OCR 信心不足時，作為智慧備援啟動。它會嘗試進行語義型的問答讀值（例如：「這台儀器上的數字是多少？」）或指示系統換備援攝影機。
◦
特色/注意事項：
▪
優點： 純 VLM 只有一條模型推理流程，系統結構較簡單。在螢幕大部分可見且語意線索足夠時，VLM 有時能推斷數字，有較好的遮擋與反光容忍度。
▪
缺點： 單張推理通常超過 300 毫秒，且需較大 GPU 記憶體，難以高幀率處理。屬於語言模型黑盒，難定位像素級錯誤來源，缺乏第二信號源，較難即時發現幻覺或讀值漂移。法規與審查難度較高。
◦
協作角色： 類似於「資深工程師」或「問題解決專家」，在主幹流程（OCR）遇到困難時介入，提供更高階的語義判斷，補足盲點。
7.
Readability Estimator (可讀性評分器)
◦
任務： 即時計算「這台攝影機看這台儀器」的**「健康分數」**。這個分數是綜合考量焦距 MTF、遮擋比例、亮度直方圖、斜率失真等因素。
◦
協作角色： 類似於「品管人員」或「數據質量分析師」，評估原始輸入數據的品質，為後續的決策提供重要依據。
8.
Fallback 決策邏輯 (Fallback Decision Logic)
◦
任務： 根據 Readability Estimator 提供的健康分數、OCR 或 VLM 的信心值以及失敗類型，智慧選擇下一步的行動。這包括：
▪
繼續使用 OCR。
▪
切換到備援鏡頭。
▪
啟動 VLM 進行辨識。
▪
執行 PTZ 攝影機的微調或巡航掃描。
◦
協作角色： 類似於「專案經理」或「智能控制器」，在遇到問題時協調資源並制定應變計畫，確保任務的持續進行和最終成功。
攝影機資料流與 SOP 的完成
以下是攝影機資料流如何在這些代理人之間移動，並完成讀值流程 (SOP) 的詳細步驟：
1.
初始資料流：持續輸入 StreamHub
◦
每台 PTZ 攝影機都會持續地將其捕獲的影像串流發送到中心的 StreamHub 節點。StreamHub 負責緩衝和管理這些實時影像數據。
2.
主來源選取
◦
在每個讀值週期開始時，系統（可能由 Fallback 決策邏輯或一個協調器驅動）會檢視來自所有攝影機的數據。
◦
Readability Estimator 會對每台攝影機當前「看」到的儀器的影像進行健康分數評估。
◦
系統會選取健康分數最高的攝影機作為該次讀值的主影像來源。
3.
儀器與螢幕預處理
◦
來自主來源攝影機的影像會被送入 儀器偵測模型。該模型負責找到影像中的儀器實例，並將其裁切出來。
◦
裁切後的儀器影像接著被送至 角點偵測模型，以找到螢幕的四個角點。
◦
根據角點計算透視矩陣，將螢幕畫面拉正後，再由 模板-ROI 切割器 根據預先定義的模板，精準地裁切出需要讀值的各個欄位（ROI）。
4.
主要讀值嘗試：OCR 管線
◦
切割好的多個 ROI 會被送入 OCR 管線。
◦
OCR 管線會對這些 ROI 進行快速的數值讀取。
◦
若 OCR 成功且其信心度達到預設的閾值，則直接將讀取到的數值存入資料庫。此時，該數值、其來源影像、以及 YOLO 的所有偵測結果都會被同時記錄下來，以確保可追溯性。
5.
備援與驗證 (Fallback 決策邏輯啟動)
◦
若 OCR 讀值失敗（例如，OCR 信心度不足、辨識結果不合理等），Fallback 決策邏輯 會根據預設的 SOP 進行備援判斷：
▪
備援攝影機嘗試： 系統會檢查是否存在其他備援攝影機，並且其對該儀器的健康分數是否達到或高於 0.60。
•
如果存在，則切換到該備援攝影機的影像，並從步驟 3 開始，再次執行儀器與螢幕預處理及 OCR 讀值流程。
▪
VLM 介入： 如果備援攝影機的 OCR 嘗試也失敗了，現場的原始影像（或相關區域）會被送至 VLM Orchestrator。
•
VLM Orchestrator 會嘗試進行語義級的辨識和問答式讀值。
•
若 VLM 的信心度達到或高於 0.90，系統則採用 VLM 的結果。此時，VLM 的完整模型回應和來源影像也會被記錄下來。
▪
PTZ 微調與人工覆核： 如果上述所有自動化方法都失敗了（OCR、備援 OCR、VLM），Fallback 決策邏輯會嘗試微調 PTZ 攝影機的角度，進行小幅的調整，或者觸發巡航掃描，以尋找更好的視角。
•
若所有嘗試都無解，則該筆讀值會被記錄為「無法辨識」，並標記為將來需要進行人工覆核。
6.
結果紀錄與追溯
◦
無論讀值最終是通過 OCR 還是 VLM 成功取得，所有的結果（數值、來源、信心度）都會被寫入資料庫，並同時保存相應的來源影像快照。
◦
這種詳細的記錄確保了「多視角一致性、稽核影像、時戳封存」的需求，使得未來可以進行回溯和稽核，滿足零遺漏、零誤抄的目標。
透過上述流程，MeterGPT 系統的各個「代理人」或模組緊密協作，不僅實現了高效、自動化的儀器讀值，還內建了多層次的驗證與備援機制，有效應對了實際應用中可能遇到的各種複雜情況（如儀器移動、遮擋、反光、讀值不確定性等）。這正是 MetaGPT 「Code = SOP(Team)」 核心理念在儀器讀值領域的具體實踐。